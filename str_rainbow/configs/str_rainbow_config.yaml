run_name: str_rainbow_grpo

# When fixed_seed=false, a random seed is chosen at runtime.
fixed_seed: false
seed: 42

collab:
  # GRPO = num_agents=1. (CoMLRL's MAGRPOTrainer supports num_agents>=1.)
  num_agents: 2

data:
  # Path is resolved relative to this config file.
  csv_path: ../../dataset/str_builder/one.csv
  split_ratio: 0.8
  spacing: 2
  local_z: 0

task:
  # Allowed blocks for agent1 (and single-agent).
  block_agent1: [black_concrete]
  # Allowed blocks for agent2 (only used when collab.num_agents=2).
  block_agent2: [white_concrete]
  # Cap accepted commands per agent (extra commands are rejected for reward).
  max_commands: 300

# Prompt templates are defined in utils/prompting.py; override here if needed.
prompt:
  # When false, omit the target ASCII grid from prompts.
  provide_graph: true
  # Use tokenizer.apply_chat_template when available.
  use_chat_template: true

external:
  # Only used when trainer.num_turns > 1.
  mode: draw_feedback
  # Include the original (turn-1) prompt after the ASCII feedback.
  original_prompt: true
  # Optionally include previous commands verbatim (usually keep false).
  previous_response: false

model:
  name: Qwen/Qwen3-4B-Instruct-2507
  tokenizer_kwargs: {}
  model_kwargs:
    trust_remote_code: true
    device_map: auto
    low_cpu_mem_usage: true
    attn_implementation: sdpa
  # dtype: bf16 | fp16 | fp32 | auto
  dtype: bf16
  gradient_checkpointing: false

trainer:
  # Set by scripts (supports [jobid] placeholder).
  output_dir: TODO
  num_train_epochs: 20
  per_device_train_batch_size: 1
  learning_rate: 1e-5
  logging_steps: 20
  save_steps: 200
  num_generations: 2
  max_new_tokens: 600
  temperature: 0.6
  top_p: 0.95
  # Set >1 to enable multi-turn training with external feedback prompts.
  num_turns: 2
  # comlrl MAGRPOConfig.joint_mode: aligned (index-aligned) | cross (Cartesian product)
  joint_mode: aligned
  # normalize_advantage: true
  # epsilon_clip: 12

debug:
  # Prints an ASCII overlay per reward call:
  # - placed blocks are shown as the first letter of the block color (W/B/R/...)
  # - missing target blocks are shown as '#'
  enabled: true
  max_prints: 1000
  # If >0, print every N reward calls (in addition to max_prints cap).
  every_n_calls: 5
  # Character for empty cells in the debug render.
  empty_char: "."
  # Print raw agent completions when true.
  raw_output: true

reward_processor:
  enabled: false
  scale_factor: 1.0
  shift: null

patches:
  generation_memory: true
  single_agent_returns: true
  force_sampling: true

wandb:
  enabled: true
  project: str_rainbow
  entity: null
  # Set by scripts (supports [jobid] placeholder).
  output_dir: TODO

output:
  save_final_model: false
  # Set by scripts (supports [jobid] placeholder).
  save_path: TODO
