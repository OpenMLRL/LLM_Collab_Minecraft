model:
  name: Qwen/Qwen3-4B-Instruct-2507
  type: qwen
  temperature: 0.6
  top_p: 0.6
  max_length: 2048
  tokenizer_kwargs: {}
  model_kwargs:
    trust_remote_code: true
    device_map: auto
    low_cpu_mem_usage: true
    attn_implementation: sdpa
  dtype: bf16
  gradient_checkpointing: false

dataset:
  name: str_builder
  type: str_builder
  csv_path: ../dataset/data.csv
  train_split: "[:]"
  spacing: 2
  local_z: 0

output:
  base_dir: output
  save_final_model: false
  save_path: output/final_model
  verbose: false

external:
  mode: position_feedback
  original_prompt: true
  previous_response: true

iac:
  num_agents: 2
  num_turns: 4
  critic_model: null
  num_train_epochs: 150
  actor_learning_rate: 2.5e-6
  critic_learning_rate: 2.5e-6
  value_loss_coef: 0.6
  value_clip_range: 0.05
  rollout_buffer_size: 1
  train_batch_size: 1
  max_new_tokens: 512
  temperature: 0.6
  top_p: 0.6
  top_k: null
  use_separate_critic: true
  discount: 0.9
  early_termination_threshold: -0.1
  eval_interval: 0
  eval_num_samples: 1
  eval_batch_size: 1
  logging_steps: 20

reward_processor:
  enabled: true
  scale_factor: 1.0
  shift: -2.0

wandb:
  project: str_builder
  entity: OpenMLRL
  run_name: str_builder_iac
  dir: output
  tags: ["iac", "str_builder"]

prompt:
  provide_graph: false
  use_chat_template: true

task:
  block_agent1: [black_concrete, green_concrete]
  block_agent2: [white_concrete, red_concrete]
  max_commands: 300

debug:
  enabled: true
  max_prints: 1000
  every_n_calls: 5
  empty_char: "."
  raw_output: true

patches:
  generation_memory: true
  single_agent_returns: true
  force_sampling: true
